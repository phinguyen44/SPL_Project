setwd("/Users/claudiaguenther/Documents/SPL_Project")
rm(list = ls())
# List all packages needed for session
neededPackages = c("dplyr", "tidyr", "ggplot2", "magrittr", "countrycode")
allPackages    = c(neededPackages %in% installed.packages()[,"Package"])
# Install packages (if not already installed)
if(!all(allPackages)) {
missingIDX = which(allPackages == FALSE)
needed     = neededPackages[missingIDX]
lapply(needed, install.packages)
}
# Load all defined packages
lapply(neededPackages, library, character.only = TRUE)
# Load dataset
load("easySHARE_rel6_0_0.rda")
dat.input = easySHARE_rel6_0_0
rm(easySHARE_rel6_0_0)
################################################################################
# ENCODE MISSING VALUES
# Organize data.frame by selecting relevant variables
dat = dat.input %>%
filter(wave == "1" & (age <= 64 & age >= 50)) %>%  # wave 1 & age filter
select(wave, country_mod,                          # dataset details
female, age, isced1997_r, ch001_, mar_stat, # demographic variables
chronic_mod, maxgrip, adla, bmi2, eurod, sphus, # health indicators
ep013_mod)                                  # labor (outcome var)
rm(dat.input)
# Encode missing values according to SHARE dataset guidelines
a = c(-2, -3, -4, -7, -9, -12, -13, -14, -15, -16)
b = c("tocheck","implausible", "tocheck", "uncoded", "notApplicable",
"dontKnow", "notAskedWave", "notAskedCountry", "noInformation",
"noDropOff")
missing.value.codes = data.frame(a,b)
# This data frame can be used to verify NA codes easily.
# But for the encoding only the numeric vector a is necessary.
# Find NA locations and declare them as such
df.decl = apply(dat, 2, function(z) {
na.loc    = which(z %in% a)
z[na.loc] = NA
return(z)
})
df = data.frame(df.decl)
# If working hours is NA, this means individuals don't work
df$ep013_mod[is.na(df$ep013_mod)] = 0
# TODO: crosscheck this with variable ep005
################################################################################
# CREATE DATA FRAMES FOR ANALYSIS AND ESTIMATION
# Get country information from "countrycode" package
country_list = c("BEL", "NLD", "FRA", "SWE", "DEU", "GRC", "ITA", "ESP", "DNK",
"AUT", "CHE")
country_data = with(countrycode_data, data.frame(iso3c, iso3n))
# Variables are cleaned, converted into human-readable naming conventions, and
# converted to dummies as described in the paper
df.out       = df %>%
dplyr::left_join(country_data, by = c("country_mod" = "iso3n")) %>%
dplyr::filter(iso3c %in% country_list) %>%
dplyr::mutate(country       = factor(iso3c),
gender        = factor(ifelse(female, "FEMALE", "MALE")),
age50_54      = age < 55,
age55_59      = age >= 55 & age < 60,
age60_64      = age >= 60,
age           = factor(floor(age)),
edu_low       = isced1997_r %in% c(0, 1),
edu_second    = isced1997_r %in% 2:4,
edu_high      = isced1997_r %in% c(5, 6),
children      = ch001_,
couple        = mar_stat %in% 1:3,
h_chronic     = chronic_mod,
h_maxgrip     = maxgrip,
h_adla        = adla > 0,
h_overweight  = bmi2 == 3,
h_obese       = bmi2 == 4,
h_badmental   = eurod > 3,
h_goodsp      = sphus < 4,
labor_ft      = ep013_mod > 32,
labor_pt      = ep013_mod < 32 & ep013_mod > 0,
labor_np      = ep013_mod == 0) %>%
dplyr::select(country, gender,              # country and gender
starts_with("age"),           # age dummy
starts_with("h_"),            # health indicators
starts_with("edu_"),          # eduction dummies
children, couple,             # demographic details
starts_with("labor_")) %>%    # labor supply outcomes
na.omit() %>%                               # remove missing values
set_rownames(NULL)                          # reset row numbering
# TODO: create a function that can read a df and print out relevant statistics
# (e.g. num rows dropped bc/ na, etc. etc, et.c). Or generalize so separate
# variables can be used. (e.g. create a standard "clean" function for working
# with the SHARE data set)
# TODO: determine threshold for "severe" and "mild" conditions (currently we
# just set it as numeric
# Create standardized variables for numeric data
standardize = function(x) {
mean = sum(x)/length(x)
std  = sd(x)
val  = (x - mean) / std
return(val)
}
# TODO: Comment in report: mention it gives same results as inbuilt function
# (scale)
# Gives a vector of integer column positions of numeric variables
idx = sapply(df.out, is.numeric)
idx = seq(1:length(idx))[idx]
# Creating separate data set with standardized numeric variables for regression,
# then reselect variables as described in paper (e.g. self-reported health is
# removed)
df.reg = df.out %>%
mutate_at(.vars = vars(idx),
.funs = standardize) %>%
mutate(labor_participation = !labor_np) %>% # invert to get labor_part rate
select(country, gender, age,
h_chronic, h_adla, h_obese, h_maxgrip,
edu_second, edu_high, children, couple,
labor_participation)
# Create a list of data frames by country and gender, to be used in regression
df.splits  = split(df.reg, f = list(df.reg$country, df.reg$gender), drop = TRUE)
# Create necessary dummary variables for regression
dummify = function(data.frame) {
data.frame = data.frame %>%
select(-country, -gender)                # remove country/gender
model      = ~ 0 + .                         # needed to remove intercept
new.df     = model.matrix(model, data.frame) # create dummies
new.df     = data.frame(new.df)
return(new.df)
}
df.splits = lapply(df.splits, dummify)
# df.out is for analysis, df.reg and df.splits are for estimation
rm(list= ls()[!(ls() %in% c("df.out", "df.splits", "df.reg"))])
rm(list= ls()[!(ls() %in% c("df.reg", "df.splits"))])
name = function(pars,object){
declarations
logl<-loglikelihoodfunction
return(-logl)
}
normal.lik1<-function(theta,y){
mu<-theta[1]
sigma2<-theta[2]
n<-nrow(y)
logl<- -.5*n*log(2*pi) -.5*n*log(sigma2) -
(1/(2*sigma2))*sum((y-mu)**2)
return(-logl)
}
optim(starting values, log-likelihood, df.reg)
optim(startingvalues, log-likelihood, df.reg)
startingvalues = rep(0,12)
optim(startingvalues, log-likelihood, df.reg)
name = function(pars,object){
declarations
logl<-loglikelihoodfunction
return(-logl)
}
startingvalues = rep(0,12)
optim(startingvalues, loglikelihood, df.reg)
name = function(pars,object){
declarations
logl<-loglikelihood
return(-logl)
}
normal.lik1<-function(theta,y){
mu<-theta[1]
sigma2<-theta[2]
n<-nrow(y)
logl<- -.5*n*log(2*pi) -.5*n*log(sigma2) -
(1/(2*sigma2))*sum((y-mu)**2)
return(-logl)
}
normal.lik2<-function(theta,y){
mu<-theta[1]
sigma<-theta[2]
n<-nrow(y)
z<-(y-mu)/sigma
logl<- -n*log(sigma) - sum(log(dnorm(z)))
return(-logl)
}
startingvalues = rep(0,12)
optim(startingvalues, loglikelihood, df.reg)
name(normal.lik2)
name = function(pars,object){
logl<-loglikelihood
return(-logl)
}
name(normal.lik2)
name = function(pars,object){
logl<-normal.lik2
return(-logl)
}
optim(startingvalues, name, df.reg)
View(name)
optim(1,normal.lik2,y=df.out,method="BFGS")
optim(1,normal.lik2,y=df.reg,method="BFGS")
optim(1,normal.lik2,y=df.reg)
?optim
optim(1, normal.lik2, y=df.reg, method="BFGS")
optim(5, normal.lik2, y=df.reg, method="BFGS")
name = function(pars,object){
logl<-normal.lik2
return(-logl)
}
normal.lik2<-function(theta,y){
mu<-theta[1]
sigma<-theta[2]
n<-nrow(y)
z<-(y-mu)/sigma
logl<- -n*log(sigma) - sum(log(dnorm(z)))
return(-logl)
}
optim(5, normal.lik2, y=df.reg, method="BFGS")
optim(c(0,1), normal.lik2, y=df.reg, method="BFGS")
optim(rep(0,12), normal.lik2, y=df.reg, method="BFGS")
optim(rep(0,12), normal.lik2, y=df.reg$labor_participation, method="BFGS")
optim(rep(0,12), normal.lik1, y=df.reg$labor_participation, method="BFGS")
optim(rep(0,12), normal.lik2, y=df.reg$labor_participation, method="BFGS")
optim(1, normal.lik2, y=df.reg$labor_participation, method="BFGS")
name<-function(pars,object){
declarations
logl<-loglikelihood function
return(-logl)
}
name<-function(pars,object){
declarations
logl<-loglikelihood
return(-logl)
}
normal.lik1<-function(theta,y){
mu<-theta[1]
sigma2<-theta[2]
n<-nrow(y)
logl<- -.5*n*log(2*pi) -.5*n*log(sigma2) -
(1/(2*sigma2))*sum((y-mu)**2)
return(-logl)
}
normal.lik2<-function(theta,y){
mu<-theta[1]
sigma<-theta[2]
n<-nrow(y)
z<-(y-mu)/sigma
logl<- -n*log(sigma) - sum(log(dnorm(z)))
return(-logl)
}
optim(1, normal.lik2, y=df.reg$labor_participation, method="BFGS")
optim(1, normal.lik2, y=df.reg$labor_participation)
optim(1, normal.lik2, y=df.reg)
optim(par = rep(1,11), fn = normal.lik2)
optim(par = rep(1,11), fn = normal.lik2, y = df.reg)
optim(par = rep(1,11), fn = normal.lik2, y = df.reg$labor_participation)
optim(par = rep(1,11), fn = normal.lik2, y = df.reg[, 5:13])
optim(par = rep(1,11), fn = normal.lik2, y = df.reg[, 5:12])
optim(par = rep(1,11), fn = normal.lik2, y = df.reg$age)
optim(par = rep(1,11), fn = normal.lik2, y = df.reg$h_maxgrip)
optim(par = rep(1,11), fn = normal.lik2, y = df.reg$h_obese)
optim(par = rep(1,11), fn = normal.lik2, y = df.reg$h_obese)
probitMLE = function(params, x, y){
beta = params
mu = x%*%b
ll = sum(y*pnorm(mu, log.p=T) + (1-y)*pnorm(-mu, log.p=T))
ll
}
outMLE = optim(init, probitMLE, X=df.reg[, c(4:11)], y=df.reg[, c(12)], control=list(fnscale=-1, maxit=1000, reltol=1e-8))  # make tolerance really low to duplicate glm result
outMLE = optim(1, probitMLE, X=df.reg[, c(4:11)], y=df.reg[, c(12)], control=list(fnscale=-1, maxit=1000, reltol=1e-8))  # make tolerance really low to duplicate glm result
coefsMLE = outMLE$pa
outMLE = optim(1, probitMLE, X=df.reg[, c(4:11)], y=df.reg[, c(12)],
control=list(fnscale=-1, maxit=1000, reltol=1e-8), gr = "BFGS")
outMLE = optim(1, probitMLE, X=df.reg[, c(4:11)], y=df.reg[, c(12)],
control=list(fnscale=-1, maxit=1000, reltol=1e-8), gr = "Brent")
outMLE = optim(1, probitMLE, X=df.reg[, c(4:11)], y=df.reg[, c(12)],
control=list(fnscale=-1, maxit=1000, reltol=1e-8))
X = as.matrix(df.splits)
View(X)
X = as.matrix(df.splits$AUT.FEMALE)
View(X)
X = as.matrix(df.splits$AUT.FEMALE)
outMLE = optim(1, probitMLE, X=X[, -24], y=X[,24],
control=list(fnscale=-1, maxit=1000, reltol=1e-8))
y = X[,24]
X = X[,1:23]
probitMLE = function(params, X, y){
beta = params
mu = X%*%b
ll = sum(y*pnorm(mu, log.p=T) + (1-y)*pnorm(-mu, log.p=T))
ll
}
outMLE = optim(1, probitMLE, X=X, y=y,
control=list(fnscale=-1, maxit=1000, reltol=1e-8))
probitMLE = function(params, X, y){
b = params
mu = X%*%b
ll = sum(y*pnorm(mu, log.p=T) + (1-y)*pnorm(-mu, log.p=T))
ll
}
outMLE = optim(1, probitMLE, X=X, y=y,
control=list(fnscale=-1, maxit=1000, reltol=1e-8))
X = as.matrix(df.splits$AUT.FEMALE)
outMLE = optim(1, probitMLE, X=X, y=y,
control=list(fnscale=-1, maxit=1000, reltol=1e-8))
y = X[,24]
X = X[,1:23]
X = as.matrix(df.splits$AUT.FEMALE)
y = X[,24]
X = X[,1:23]
outMLE = optim(1, probitMLE, X=X, y=y,
control=list(fnscale=-1, maxit=1000, reltol=1e-8))
pll <- function(beta){
sum(y*log(pnorm(X %*% beta)) + (1-y)*log(1-pnorm(X %*% beta)))
}
system.time(ml1 <- optim(coef(aa)*2.5, pll, method="BFGS",
control=list(maxit=5000, fnscale=-1), hessian=T))
aa <- lm(formula,data)
formula= labor_participation ~ .
data=df.splits$AUT.FEMALE
aa <- lm(formula,data)
formula= y ~ X.
data=df.splits$AUT.FEMALE
aa <- lm(formula,data)
X = as.matrix(df.splits$AUT.FEMALE)
y = X[,24]
X = X[,1:23]
formula= y ~ X.
data=df.splits$AUT.FEMALE
aa <- lm(formula,data)
pll <- function(beta){
sum(y*log(pnorm(X %*% beta)) + (1-y)*log(1-pnorm(X %*% beta)))
}
aa = lm(formula,data)
system.time(ml1 <- optim(coef(aa)*2.5, pll, method="BFGS",
control=list(maxit=5000, fnscale=-1), hessian=T))
formula= y ~ X
data=df.splits$AUT.FEMALE
aa <- lm(formula,data)
pll <- function(beta){
sum(y*log(pnorm(X %*% beta)) + (1-y)*log(1-pnorm(X %*% beta)))
}
aa = lm(formula,data)
system.time(ml1 <- optim(coef(aa)*2.5, pll, method="BFGS",
control=list(maxit=5000, fnscale=-1), hessian=T))
system.time(ml1 <- optim(coef(aa), pll, method="BFGS",
control=list(maxit=5000, fnscale=-1), hessian=T))
system.time(ml1 <- optim(coef(aa), pll, method="BFGS",
hessian=T))
ml1 = optim(coef(aa), pll, method="BFGS",
hessian=T)
ml1 = optim(coef(aa), pll,
hessian=T)
Z = df.splits$AUT.FEMALE
formula= Z ~ .
data=
aa <- lm(formula,data)
Z = as.matrix(df.splits$AUT.FEMALE)
formula= Z ~ .
data= Z
aa <- lm(formula,data)
Z = as.data.frame(df.splits$AUT.FEMALE)
formula= Z ~ .
data= Z
aa <- lm(formula,data)
typeof(Z)
Z = as.data.frame(df.splits$AUT.FEMALE)
formula= Z ~ .
data= Z
aa <- lm(formula,data)
pll <- function(beta){
sum(y*log(pnorm(X %*% beta)) + (1-y)*log(1-pnorm(X %*% beta)))
}
Z = as.data.frame(df.splits$AUT.FEMALE)
typeof(Z)
Z = data.frame(df.splits$AUT.FEMALE)
typeof(Z)
View(Z)
Z = data.frame(df.splits$AUT.FEMALE)
Z = dataframe(df.splits$AUT.FEMALE)
Z = data.frame(df.splits$AUT.FEMALE)
Z = as.matrix(df.splits$AUT.FEMALE)
Z = data.frame(Z)
typeof(Z)
Z = do.call(rbind.data.frame, df.splits$AUT.FEMALE)
formula= Z ~ .
data= Z
aa <- lm(formula,data)
typeof(Z)
df <- ldply (Z, data.frame)
library(ldply)
Z= data.frame(t(sapply(Z,c)))
formula= Z ~ .
data= Z
aa <- lm(formula,data)
Z= data.frame(Reduce(rbind, Z))
formula= Z ~ .
data= Z
aa <- lm(formula,data)
M= data.frame(Reduce(rbind, Z))
Z = M
formula= Z ~ .
data= Z
aa <- lm(formula,data)
pll <- function(beta){
sum(y*log(pnorm(X %*% beta)) + (1-y)*log(1-pnorm(X %*% beta)))
}
K = ncol(X)
View(X)
y
vi <- lm(y ~ .)$coefficients
K = ncol(X)
View(X)
y = matrix(y)
View(y)
View(X)
names(X)
colnames(X)
vi <- lm(V1 ~ colnames(X))$coefficients
vi <- lm(y ~ colnames(X))$coefficients
X= X[,2]
X = as.matrix(df.splits$AUT.FEMALE)
X= X[,2:4]
X= X[,5:8]
View(X)
K = ncol(X)
vi <- lm(y ~ age51, age52, age53)$coefficients
View(X)
vi <- lm(y ~ age51 + age52 + age53)$coefficients
probit.nll <- function (beta) {
exb <- exp(X%*%beta)
prob<- rnorm(exb)
logexb <- log(prob)
y0 <- (1-y)
logexb0 <- log(1-prob)
yt <- t(y)
y0t <- t(y0)
-sum(yt%*%logexb + y0t%*%logexb0)
}
probit.gr <- function (beta) {
grad <- numeric(K)
exb <- exp(X%*%beta)
prob <- rnorm(exb)
for (k in 1:K) grad[k] <- sum(X[,k]*(y - prob))
return(-grad)
}
fit <- optim(vi, probit.nll, gr = probit.gr, method = "BFGS", hessian =  TRUE)
fit <- optim(c(1:3), probit.nll, gr = probit.gr, method = "BFGS", hessian =  TRUE)
fit
X = as.matrix(df.splits$AUT.FEMALE)
X= X[,20:22]
K = ncol(X)
vi <- lm(y ~ age51 + age52 + age53)$coefficients
probit.nll <- function (beta) {
exb <- exp(X%*%beta)
prob<- rnorm(exb)
logexb <- log(prob)
y0 <- (1-y)
logexb0 <- log(1-prob)
yt <- t(y)
y0t <- t(y0)
-sum(yt%*%logexb + y0t%*%logexb0)
}
probit.gr <- function (beta) {
grad <- numeric(K)
exb <- exp(X%*%beta)
prob <- rnorm(exb)
for (k in 1:K) grad[k] <- sum(X[,k]*(y - prob))
return(-grad)
}
fit <- optim(c(1:3), probit.nll, gr = probit.gr, method = "BFGS", hessian =  TRUE)
