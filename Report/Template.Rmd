---
title: "Analysis and Graphical Representation of Health and  
Labour Force Participation among the Elderly in Europe"
header-includes:
  - \usepackage{graphicx}
  - \usepackage{amsmath}
  - \usepackage{float}
  - \usepackage{hyperref}
  - \usepackage{setspace}
  - \usepackage{booktabs}
  - \onehalfspacing
output: pdf_document
latex_engine: lualatex
geometry: margin = 2.5cm
bibliography: references.bib
---

```{r setup, eval = TRUE, echo = FALSE, include = TRUE}
wd = paste0(Sys.getenv("HOME"), "/Documents/SPL_Project")
knitr::opts_knit$set(root.dir = wd)

```

```{r global_options, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(fig.pos = 'H')
getwd()





```
\pagenumbering{gobble}


\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
            {-2.5ex\@plus -1ex \@minus -.25ex}%
            {1.25ex \@plus .25ex}%
            {\normalfont\normalsize\bfseries}}
\makeatother
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}    

\bigskip

\begin{center}


Humboldt-Universität zu Berlin \linebreak     
School of Business and Economics  \linebreak
Ladislaus von Bortkiewicz Chair of Statistics   \linebreak
\medskip


\includegraphics[width=0.2\textwidth]{HU_Logo_small.png}


\textbf{Statistical Programming Languages} \linebreak
Winter 2017/18

\medskip


Seminar Paper by  \linebreak  

\textbf{Claudia Günther, Phi Nguyen, Julian Winkel}  \linebreak  
576419, 526624, 562959 \linebreak

\medskip

\medskip


Berlin, 2018-03-15 \linebreak

\end{center}

\medskip

\medskip

\newpage

\listoftables

\newpage

\listoffigures

\newpage


\begin{Large}
\textbf{Abbreviations} \linebreak
\end{Large}

\begin{tabular}{ll}
\textbf{XX} & XXXXXXXXXX     \\

\end{tabular}


\newpage

\pagenumbering{arabic}

\tableofcontents

\newpage

\section{Introduction}

- relevance of exploring relationship between health and labour force participation due to changing demographic in Europe
- cite relevant study about ageing 
- few sentences about relevant papers exploring relationship -> use paper from DIW
- very short literature overview on relationship between health and labour force participation
- share data set as rich data set for this purpose: 2 sentences about it
- introduction of journal article 
- our approach: replicate results an enrich analysis
- especially: introduce graphical visualization tools for descriptive statistics -> ease interpretation of variables
- our aim: write code in a way that allows the user to work with easySHARE data set, even when working on different question

\newpage

\section{Panel data cleaning and subsetting}
PHI
\subsection{Theory and Design}
\subsection{Implementation}
\subsection{Empirical Results}


The easySHARE dataset released in spring 2017 is a panel dataset of 108 variables of more than 100.000 individuals covering data from six survey waves carried out between 2004 and 2005. As we are only concerned with a small subset of observations, an important task was to define appropriate functions for subsetting. In oder to make our subsetting process understandable to readers, we decided on using pipe-operator. This allows us to apply the filter and select option in a clever way, where we can select different criteria at once. 

-> code sniplet here

In this example, we first filter for participation in wave 1 and the age group between 50 and 64 and the select the desired variables as described in Kalwij and Vermeulen (2005).

Although the overall response rate in the SHARE are comparably high, the data set still has numerous missing values. The reason for this is due to the fact that the study was carried out on a crossnational scale, with some national survey institutions deciding not to participate in all survey modules. This means that the majority of missing values are to be found within observations that have missing values for entire survey modules or waves. The reason for the missing values are documented well in the "Guide to easySHARE release 6.0.0" and specifically coded. For example, the numbers -13 and -14 refer to “not asked in this wave” and “not asked in this country”. Since this coding scheme is not useful for the purpose of our analysis, we decided on recoding all of the missing values as "NA". To this end, we defined a function based on the missing codes provided by SHARE that finds the NAs in the data and declares them as such. 

-> code snipet here

Since the study carried out by Kalwij and Vermeulen (2005) is based on the use of mostly binary data, we needed to construct numerous dummies based on the orginal data. 

-> code snipet here

The resulting dataframe containes XXX observations of YYY variables.  

- coded countries in more readable manner
- use packe ddd -> match offical ISO code with country name
- create country list with all countries in study (not Israel)
- defined dummies

\section{Multidisciplinary and crossnational summary statistics}
JULIAN
\subsection{Theory and Design}
\subsection{Implementation}
\subsection{Empirical Results}


\newpage

\section{Crosssectional probit regression}
JULIAN
\subsection{Theory and Design}
\subsection{Implementation}
\subsection{Empirical Results}


\newpage

\section{Wald Test}
In the context of probit regression, the Wald test can be used to test multiple hypothesis regarding the model specifications and significance of coefficients. For example, it can be used to test whether the fit of the model is improved if a subset of regression coefficients are all set equal to zero, an exclusion restriction. @kalwij2005labour conduct a Wald test to check the null hypothesis that none of the included health variables has an impact on labour participation in order to investigate the joint impact of health on participation.

\subsection{Theory and Design}
Depending on the estimation method and distributional assumptions, the Wald statistic can be formulated in different ways. The general form of the Wald statistic after MLE for testing hypothesis regarding our $k \times 1$ parameter vector $\theta$ is given by
$$
W = c(\hat{\theta})'[\nabla_{\theta}c(\hat{\theta})\hat{V}\nabla_{\theta}c(\hat{\theta})]^{-1}c(\hat{\theta})
\tag{***}
$$


where $c(\hat{\theta})$ is a $m \times 1$ vector of linear or nonlinear restrictions, $\nabla_{\theta}c(\hat{\theta})$ is the $m \times k$ Jacobian of $c(\hat{\theta})$ evaluated
at $\hat{\theta}$ and $\hat{V}$ is the estimated asymtotic covariance matrix [@wooldridge2010econometric, 463]. Under H0, the Wald test statistic is asymptotically $\chi2_m$ distributed, with m being the number of specified restrictions. In order to assure the test statistic W has the assumed limiting distribution, we need to impose some practical restrictions. Under H0, $\theta$ must lie within parameter space and R must be of rank m [@wooldridge2010econometric, 362].
We limit our attention to testing a set of general linear restrictions since the Wald test is not invariant to the re-formulation of non-linear hypothesis [@wooldridge2010econometric, 362]. We thus formulate our nullhypothesis in accordance with the common linear restriction structure of H0: $R \hat{\beta} = r$ againsts the alternative H1:  $R \hat{\beta} \neq r$ to facilitate the derivation of our test statistics where R is a $m \times k$ matrix of rank m (equivalent to the Jacobian), whereas the restriction function r is a $m \times 1$ vector. Given the above technical conditions are satisfied, the Wald statistic can then be rewritten as
$$    W = (R \hat{\beta} - r)'[R \hat{V}R']^{-1}(R \hat{\beta} - r)
\tag{***}
$$
which facilitates our calculations [@greene2012econometric, 527-529; @wooldridge2010econometric, 362]. When we are interested in the joint significance of a subset of s coefficients, the nullhypothesis is that each of the s coefficients in the vector $\beta_s$ is equal to zero. The Wald test statistic $W \stackrel{a}{\sim}\chi2_s$ can then be even more simplified [@wooldridge2010econometric, 362]:
 $$   W = \hat{\beta}_s'[R\hat{V}R']^{-1}\hat{\beta}_s = \hat{\beta}_s'[\hat{V}_s]^{-1}\hat{\beta}_s
 \tag{***}
 $$
\subsection{Implementation}
In order to test linear hypothesis regarding the model specifications and significance of coefficients we design two versions of a Wald test. The function `joint.wald.test` is a simplied version to test the joint significance of a subset of model coefficients, whereas `general.wald.test` allows checking any linear hypothesis. The two tests are constructed in a way so they align well with the general glm estimation output, especially relevant for probit regression. The specific design of the joint significance test `joint.wald.test` is makes the function easy to use, understand and modify to special needs. The only required input is the model summary from glm estimation, whereas the significance level and test specifications are optional. 
```{r eval=FALSE}
joint.wald.test = function(model.summary, signf.level = 0.95, spec = NULL){
    
    joint.wald.test        = numeric(6)
    names(joint.wald.test) = c("Name","W","p-value", "df", "H0" , "Decision")
    beta                   = model.summary$coefficients[,1]
    Var_beta_est           = vcov(model.summary)
    
```
In order to set up default values for the hypothesis specification, we make use of a local if-else statement inside the ``` joint.wald.test``` function. By declaring the model specification to be null in line XXX we set the foundation for the default specification in line XXX - XXX. Here, we re-asign a sequence vector to the ```spec``` that includes the number of all model coefficients in increasing order, unless ```spec``` is specified differently by the user. In that case, the if-else statement will use the user specification assured by line XXX.

```{r eval=FALSE}
        spec = if (is.null(spec)){
        spec = 1: length(beta) # default is joint significance test
    }
```
This means that ``` joint.wald.test``` function will conduct a joint significance test on all model coefficients by default. We setup a default significance level of 95% in the same manner. The Wald test statistic is calculated via simple matrix algebra based on the provided input by the model summary. This formula is equivalent to equation YYY. 

```{r eval=FALSE}
    W = t(beta[spec]) %*% solve(Var_beta_est[spec,spec]) %*% beta[spec]
    
```
As can be seen in line XXX the proper format of the specification vector ```spec``` is crucial as it is used to extract the needed estimates from the model coeffictient vector and covariance matrix.   In line XXX, the term ```Var_beta_est[spec,spec]``` extracts all covariance matrix elements corresponding to the joint significance hypothesis of the particular specification. To assure the proper extraction of the covariance elements and determination of degrees of freedom in line XXX,  ```spec``` must be a vector of integers of length $0< m \leq k$.
```{r eval=FALSE}  
    chi2               = qchisq(signf.level, df = length(spec))
    pval               = 1-pchisq(W,length(spec))
    joint.wald.test[1] = "Chi2 test"
    joint.wald.test[2] = format(   W, digits = 4) 
    joint.wald.test[3] = format(pval, digits = 4)
    joint.wald.test[4] = length(spec)
    joint.wald.test[5] = "b equal to 0"
    joint.wald.test[6] = ifelse(pval <= 1- signf.level, "Reject H0", "Cannot reject H0")
    joint.wald.test
```  
As a last step we set up the test ouput by assigning values to the empty vector elements of ``` joint.wald.test```. This vector will be the function output that is returned. We determine the critical value and p-value in lines XXX-XXX based on the inbuilt ``` qchisq``` and display four significant decimal places. As can be seen in lines XX, we do not only list the test statistic and p-value but also the degrees of freedom, nullhypothesis and test decision as output to assure comprehensibility and correctness of the test.

The general Wald test is designed in a similar manner, except that it allows for the general formulation of linear hypothesis of the form $R \hat{\beta} = r$. The test statistic in this case is giving by equation YYY. As in the `joint.wald.test` function, we use local local if-else statements to setup a default settings. If only the model summary is given as an input, the `general.wald.test` conducts a joint significance test at a 95% significance level. 
The crucial part to the proper usage of this function are the correctly specified Jacobian matrix R and restriction vector r, which must be of size $m \times k$ and $m \times 1$ respectively. To assure the proper asymptotic distribution of the test statistic, we additional need to assure that R is of rank m.
We therefore incorporate stops and warning messages in both wald test functions. For the case of the `general.wald.test`, we first check in line XXX whether the `model.summary` has the right class and whether the significance level lies between one and zero. Otherwise, the function's executions will be stopped. In the second step, we make sure the matrix `R`and the restriction vector `r` have matching dimension. We first extract the matrix dimensions `dim_R` in line XXX and check them via indexing in line XXX-XXX.

```{r eval=FALSE}  
    if(class(model.summary) != "summary.glm") stop("model.summary must be a glm summary!")
    if(signf.level > 1 | signf.level < 0) stop("signf.level out of bounds!")

    dim_R = dim(R)
        m = length(r)
   
    if(dim_R[1] != m | dim_R[2] != k) stop("R has wrong dimension!")
    if(rankMatrix(R)[1] != m) stop("R has wrong rank!")
```

\subsection{Empirical Results}
We use our designed wald test functions to carry out several hypothesis test on our model coefficients from probit estimation. Speficically, we check the null hypothesis that none of the four included health variables has an impact on labour participation for each country and for both men an women. The results for men can be seen in table XXX 


Our results our in line with the findings of @kalwij2005labour. As expected, the null hypothesis of no impact of health on labour participation is rejected at a 95% level for most countries. A particularity is the high p-value of France, leading to the inability to reject H0, which stands in contrast to the findings of @kalwij2005labour. We explain this with our differing sample, which is almost 50% larger and the lower overall employmen rate of our sample. Regarding the Wald tests for women, our results are very similar to those @kalwij2005labour. As for men, The majority of null hypothesis can be rejected for women, with the null for German women being barely not rejected. The inability to reject the null for some countries is due to relatively low health-related probit coefficients (in absolute terms), which implies that these health indicators are not strongly related with the labor particpation decision.
The results of our ``` joint.wald.test``` function are comparable those of our packages, like the ``` wald.test``` from the aod packages. To check our function this we can conduct both test on all subsets. For example, for German women the aod packages gives the following output

```{r eval=FALSE}
wald.test(Sigma = vcov(allModels$Germany.FEMALE), 
          b = allModels$Germany.FEMALE$coefficients, Terms = 16:19)
          
Wald test:
----------
Chi-squared test:
X2 = 9.2, df = 4, P(> X2) = 0.057
``` 
 
 
Equivalently, our `joint.wald.test` function return as output

```{r eval=FALSE} 
joint.wald.test(allSummaries$Germany.FEMALE, spec = 16:19)

  Test          W         p-value        df      H0              Decision
 "Wald"       "9.17"     "0.0569"       "4"     "b equal to 0"  "Cannot reject H0""
``` 

A weakness of the aod package is, that its wald test cannot deal with empty classes. For the case of Switzerland, where our male sample does not include any 64-year-olds, the ``` wald.test``` from the aod packages lead to the error message

```{r eval=FALSE}
wald.test(Sigma = vcov(allModels$Switzerland.MALE), 
          b = allModels$Switzerland.MALE$coefficients, Terms = 16:19 )
[1] Error in L %*% V : non-conformable arguments
``` 
Our wald test function is robust against the presence of empty classes since we work with model summaries, meaning that the coefficients of empty classes have been dropped instead of being a missing value. Thus, our `joint.wald.test` function can conduct the test for Swiss men without errors: 

```{r eval=FALSE}
joint.wald.test(allSummaries$Switzerland.MALE, spec = 16:19)
``` 
```{r echo=FALSE, eval = TRUE, results = "asis", warning = FALSE, message = FALSE}
invisible(capture.output(source("Scripts/ReadAndClean.R")))
invisible(source("Scripts/LoadWald.R"))
invisible(capture.output(source("Scripts/ProbitRegression.R")))
invisible(source("Scripts/LoadWald.R"))
joint.wald.test(allSummaries$Switzerland.MALE, spec = 16:19)
``` 

Both our wald test functions are sensitive to the improper formulation of tested model restrictions. For example, the `general.wald.test` function stop from execution if the Jacobian matrix `R` and the restriction vector `r` have non-matching dimensions. In this example, 
```{r echo=TRUE, eval = FALSE, results = "asis", warning = FALSE, message = FALSE}
matrix.R     = diag(1, 23)
vector.wrong = rep(1,22)
vector.right = rep(1,23)
general.wald.test(allSummaries$Switzerland.MALE, R = matrix.R, r = vector.wrong)
general.wald.test(allSummaries$Switzerland.MALE, R = matrix.R, r = vector.right)

``` 
In this example, `R`is an identity matrix of size $23 \times 23$, whereas `vector.wrong` is $22 \times 1$. As soon as we add another element to the `r` vector, the function works properly.

\newpage
\section{Counterfactual exercise}

Counterfactual exercises are a common tool in economic policy analysis that allow assessing and quantifying possible effects of policies. In order to evaluate the quantitative importance of a healthy population on labour participation, @kalwij2005labour conduct a counterfactual exercise. They compare the current national employment rate to the predicted counterfactual rate. This counterfactual employment rate is obtained by asuming that all individuals are in perfect health. According to their definition, a perfectly healthy individual has never had a severe or mild medical 
condition, suffers from no restrictions in activities of daily living, is not obese and has a grip strength of an average 50-51 year-old (fe)male individual.

\subsection{Theory and Design}
Counterfactual exercises based on regression methods that can be carried out in different ways (see Chernozhukov et al 2013).
The simplest method to is to replace the existing covariates values $X$ with counterfactual values $X_{cf}$. For the case of probit regression with a binary response variable $y$ for employment, we can interpret the fitted values $\hat{y}$ and $\hat{y}_{cf}$ as current and counterfactual employment probabilities for each individual. Based on these calculated individual employment probabilities, we can calculate the current and counterfactual population employment rates ($\Pi_{ac}$, $\Pi_{cf}$) by taking the mean, making use of the Law of Large Numbers. 
Obtaining the counterfactual probabilities $\hat{y}_{cf}$ requires a two-step procedure. First, the regular probit regression of $y$ on $X$ is tun to obtain the estimated coefficients $\hat{\beta}$. Second, the counterfactual probabilities for each individuals $\Pi_i$ are calculated by predicting y based on $X_{cf}$ and the estimated coefficients.  

$$ \Pi_{icf} = Pr(Yi=1|Xi=xi_{cf}) =  \Phi(xi_{cf}'{\beta}\tag{***}) $$

We can then assess counterfactual health-related effects by comparing the actual and counterfactual employment rates $\Pi_{ac}$ and $\Pi_{cf}$. We can gain closer insights into the nonlinear relation between health effects and particpation by calculating $\Pi_{ac}$ and $\Pi_{cf}$ for different age groups. This also allows assessing the proportion of decline in participation that is due to decline in health condition according to our model estimates. 
<!--\1
Optional text: Not that important
@kalwij2005labour define this measure $\delta_{decline}$ as
$$ \delta_{decline} =  \frac{\Pi_{cf}[age60.64]- \Pi_{ac}[age60.64] -   \Pi_{cf}[age50.54]- \Pi_{ac}[age50.54]}{\Pi_{ac}[age50.54] - \Pi_{ac}[age60.64]} \tag{***}$$
where $\Pi_{cf}[age60.64]$ and $\Pi_{ac}[age60.64]$ refer to the counterfactual and actual employment rates of 60 to 64 year old individuals. Though this measure is  oversimplified since XXXXXXXXX,
It nevertheless gives us a first hint towards the size of participation decline among elderly that is associated with declinning health conditions.
\1-->

\subsection{Implementation}
Our counterfactual effects are based on the manipulation of explanatory variables according to some specified criteria. We design this counterfactual exercise in a way that allows us to directly use the output from our probit estimation. As a first step, we create a simple function ```empl.rate``` that takes an estimation model object as input and predicts the employment rate, i.e. the mean of fitted values, as an output. In order to calculate the both current and counterfactual employment rates  $\Pi_{ac}$ and $\Pi_{cf}$ conveniently, we need to manipulate the original covariates contained in our model objects. For this purpose we design the function ```X.cf```, whose only input the model object, allowing us to treat each country separately later on. As can be seen in line XXX, the function creates a duplicate version of orginal data `X`, whose values will be replaced later on.


In line XXX, we calculate the minimum value for each variable in `X`, which corresponds to the perfect health 
conditions of the variables `h_chronic`, `h_adlaTRUE`, and `h_obeseTRUE` since we are dealing with standarized varaibles. We obtain these values with making use of the apply function and store them in the vector `X_min`. We also calculate the mean average grip strength of 50- to 51-years old in the sample `X`. As can be seen in line XXX, we derive this mean with the `tapply` command because it allows us to specify an age group index and returns a vector whose elements we can access.




```{r echo=TRUE, eval = FALSE, results = "asis", warning = FALSE, message = FALSE}

    X                   = model$data
    X_cf                = X
   
    X_min               = data.frame(t(apply(X, 2, min)))

    names.vec           = c("h_chronic", "h_adlaTRUE", "h_obeseTRUE")
    X_cf[, names.vec]   = X_min[names.vec]
    
        age_50_51          = ifelse(X$age50 == 1 | X$age51 == 1, 1,0)
        
    X_cf[, c("h_maxgrip")] =  tapply(X$h_maxgrip, age_50_51 == 1, mean)[[2]]
    
              model$data   = X_cf

```
Quantlet 4[![Quantlet 4](Images/qletlogo.png)](https://github.com/phister/SPL_Project/blob/master/Scripts/LoadWald.R){width=25px}
   

To obtain the counterfactual covariates, the values in `X_cf` are replaced with perfect health values. As a final step, we replace the original model data in `X_cf`. This allows us to access both the model estimates and counterfactual covariates in one object. By running our ```empl.rate``` function on the returned model, we directly optain the counterfactual employment rate for a given country.

Since we are also interested in the current and counterfactual employment rates of different age groups, we create a more advanced function ```empl.rate.age```. This function  displayed in line XXX requires the estimation model as mandatory argument and has two optional arguments (`group.size` and `group.low`) that allow to change the age group and group sizes. Given the specified arguments, the function then calculates the current and counterfactual employment rate for each age group.

```{r echo=TRUE, eval = FALSE, results = "asis", warning = FALSE, message = FALSE}
empl.rate.age        = function(model, group.size = 5, group.low = c(50,55,60)){

    X                = model$data
    
    empl.probability = predict(object = model, newdata =  X, type = "response")

```
The proper value assignment of the numerical vector `group.low` is essential since the dynamic creation of age groups is based on it. As can be seen in line XXX, we use a small for loop to determine the upper age group bound and create a label of each age group. Furthermore, we assign all of the corresponding age values (e.g. `age50`, `age51`) to the vector `z`, which correspond to the age variable names in `X`.

```{r echo=TRUE, eval = FALSE, results = "asis", warning = FALSE, message = FALSE}
        for (i in group.low){
                                k = i + group.size -1
                        vec.label = paste("names.vec.age", i, sep=".") 
                                z = assign(vec.label, paste0("age",i:k))
```
We need to assign the age values to `z` in order to locate the right individuals in our data frame `X`. We find the individuals belonging to a given age group by summing over rows of `X` and storing this vector inside the list `IND_row_vec` displayed in line XXX. We can take the sum because the age values assigned to `z` correspond to the column names of the data frame `X`. Thus, for a given individual, the row sum of `X[, z]` is either zero or one, dependong on wether the individual belongs to the age group or not. Following this step, we filter out only the relevant age groups via indexing.
```{r echo=TRUE, eval = FALSE, results = "asis", warning = FALSE, message = FALSE}
                 IND_row_vec[[i]] = apply(X[, z], 1, sum)
                 IND_row_vec      = IND_row_vec[group.low]
                 
     empl.rate[k] = empl.probability %*% IND_row_vec[[k]] / sum(IND_row_vec[[k]])

```
Finally, the employment rate for each age group is calculate in line XXX. For this, we first sum the predicted employment probability for all individuals in age group k via vector multiplication. Next, we devide this sum by the overall number of individuals in that age group, corresponding to the vector length `IND_row_vec[[k]]`.

Running the ```empl.rate.age``` function on a given model object will return a numerical vector containing the employment rate of the specified age groups.

\subsection{Empirical Results}
Running our created counterfactual functions on all the created subsamples allows us to assess the labor participation potential of a healthy population for different countries and both genders. Table XXX display these results on an aggregate level. On average, the predicted participation rate is 4.5 percentage points given the perfectly healthy individuals (certeris paribus), although there are quite some outliers. For Dutch women, the estimated counterfactual participation rate is 8 percentage point higher, corresponding to a relative increase of 18%. This is due to the high coefficients of chronic disease and obeseness in absolute terms, combined with above average prevalence of chronic disease and obeseness among Dutch women. For men, the results are even more pronounced. In Spain, for example, the counterfactual participation rate is almost 12 percentage points higher, driven by high coefficients of chronic disease, medical conditions and obeseness in absolute terms. As expected, our results are in line with @kalwij2005labour general, though the estimated participations rates differ for some countries, as a result of differing samples. 

```{r echo=FALSE, eval = TRUE, results = "asis", warning = FALSE, message = FALSE}

# SOURCE DATA

invisible(capture.output(source("Scripts/Counterfactual.R")))

# Store results and display them
employment            = data.frame(cbind(unlist(empl.current), unlist(empl.counterfact)))
colnames(employment)  = c("Employment Current" , "Employment Counterfactual.") 
library(stringr)
rownames(employment)  = str_sub(rownames(employment), end= -8)
knitr::kable(employment[1:11,], caption = "Women's current and counterfactual labor share",
            digits = 2, align = "c")
```

It must be stressed, however, that the counterfactual estimates presented by @kalwij2005labour should be interpreted with caution. First of all, the transformation of the status quo populations with perfectly health individuals is articial and represents a state that could not realistically be reached with any policy. Second, some of the high counterfactual rates are driven by relatively high model coefficients that are not statistically significant, indicating non-robust results. Third, the aggregate country estimates do not properly display the variation of health effects among different age groups. In order to address this, we also analyze the results of the counterfactual exercise with help of our ```empl.rate.age``` function. The output of this for men is displayed in table XXX. As expected, both the current and counterfactual labor shares decrease at higher age. The difference between current and counterfactual shares is also increasing in age, though some exceptions (Austria, Italy and Greece) exist. This increasing difference points towards the negative health effects on labor associated with increasing age. Again, our results are in line with those obtained by @kalwij2005labour. 


```{r echo = FALSE, eval = TRUE, results = "asis", warning = FALSE, message = FALSE}

# SOURCE DATA

invisible(capture.output(source("Scripts/Counterfactual.R")))

# Store results and display them

empl.current.age     = t(data.frame(lapply(allModels, empl.rate.age)))
empl.counterfact.age = t(data.frame(lapply(allModels.cf, empl.rate.age)))
employment.age           = data.frame(cbind(empl.current.age, empl.counterfact.age))
colnames(employment.age) = paste(c(rep("Current", 3) , rep( "CF", 3)), 
                                  c("50-54","55-59", "60-64"))
#Reorder colums
new.order = c(1,4,2,5,3,6)
employment.age    = employment.age[,new.order]

library(stringr)
rownames(employment.age)  = str_sub(rownames(employment.age), end= -6)
knitr::kable(employment.age[12:22,], caption = "Men's current and counterfactual (CF) labor share for different age groups", digits = 2, align = "l")

```


\newpage

\section{Graphical representation}
PHI
\subsection{Theory and Design}
\subsection{Implementation}
\subsection{Empirical Results}


\newpage


\section{Conclusion}





\newpage

\section{References}


<div id="refs"></div>


\newpage

\begin{Large}
\textbf{Declaration of Authorship}
\end{Large}

\bigskip
\bigskip

We hereby confirm that we have authored this Seminar paper independently and without use
of others than the indicated sources. All passages which are literally or in general matter taken
out of publications or other sources are marked as such.
\bigskip

Berlin, 2018-03-15 

\smallskip

Claudia Günther, Phi Nguyen, Julian Winkel
\bigskip

